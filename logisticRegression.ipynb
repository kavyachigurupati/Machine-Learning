{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Kavya Chigurupati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.datasets as ds\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "%matplotlib inline\n",
    "import re\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy is library for scientific computing in Python. It has efficient implementation of n-dimensional array (tensor) manupulations, which is useful for machine learning applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert a list into numpy array (tensor)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 4],\n",
       "       [2, 6, 9]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = [[1, 2, 4], [2, 6, 9]]\n",
    "a = np.array(b)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the dimensions of the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply simple arithmetic operation on all element of a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  6, 12],\n",
       "       [ 6, 18, 27]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a * 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can transpose a tensor\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [2, 6],\n",
       "       [4, 9]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(a.T.shape)\n",
    "a.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can apply aggregate functions on the whole tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or on one dimension of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  8, 13])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(a, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7, 17])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(a, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do element-wise arithmetic operation on two tensors (of the same size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  6, 20],\n",
       "       [ 2, 12,  9]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1 = np.array([[1, 2, 4], [2, 6, 9]])\n",
    "c2 = np.array([[2, 3, 5], [1, 2, 1]])\n",
    "c1 * c2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to multiply all columns of a tensor by vector (for example if you want to multiply all data features by their lables) you need a trick. This multiplication shows up in calculating the gradients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 4]\n",
      " [2 6 9]]\n",
      "[ 1 -1]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1, 2, 4], [2, 6, 9]])\n",
    "b = np.array([1,-1])\n",
    "print(a)\n",
    "print(b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we want to multiply the first row of a by 1 and the second row of a by -1. Simply multiplying a by b does not work because a and b do not have the same dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this multiplication we first have to assume b has one column and then repeat the column of b with the number of columns in a. We use tile function to do that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1,  1,  1],\n",
       "       [-1, -1, -1]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_repeat = np.tile(b,  (a.shape[1],1)).T\n",
    "print(b_repeat.shape)\n",
    "b_repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can multiply each column of a by b:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  4],\n",
       "       [-2, -6, -9]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a * b_repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create inital random vector using numpy (using N(0,1)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 0 #mean\n",
    "sigma = 1 #standard deviation\n",
    "r = np.random.normal(mu,sigma, 1000) #draws 1000 samples from a normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply functions on tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementation of Normal distribution\n",
    "def normal(x, mu, sigma):\n",
    "    return np.exp( -0.5 * ((x-mu)/sigma)**2)/np.sqrt(2.0*np.pi*sigma**2)\n",
    "\n",
    "#probability of samples on the Normal distribution\n",
    "probabilities = normal(r, mu, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy has useful APIs for analysis. Here we plot the histogram of samples and also plot the probabilies to see if the samples follow the normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fa7d8bce970>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts, bins = np.histogram(r,50,density=True)\n",
    "plt.hist(bins[:-1], bins, weights=counts)\n",
    "plt.scatter(r, probabilities, c='b', marker='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    f = open(filename, 'r')\n",
    "    p = re.compile(',')\n",
    "    xdata = []\n",
    "    ydata = []\n",
    "    header = f.readline().strip()\n",
    "    varnames = p.split(header)\n",
    "    namehash = {}\n",
    "    for l in f:\n",
    "        li = p.split(l.strip())\n",
    "        xdata.append([float(x) for x in li[:-1]])\n",
    "        ydata.append(float(li[-1]))\n",
    "    \n",
    "    return np.array(xdata), np.array(ydata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming our data is x is available in numpy we use numpy to implement logistic regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "(xtrain_whole, ytrain_whole) = read_data('datasets/spambase-train.csv')\n",
    "(xtest, ytest) = read_data('datasets/spambase-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of xtrain: (3601, 54)\n",
      "The shape of ytrain: (3601,)\n",
      "The shape of xtest: (1000, 54)\n",
      "The shape of ytest: (1000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"The shape of xtrain:\", xtrain_whole.shape)\n",
    "print(\"The shape of ytrain:\", ytrain_whole.shape)\n",
    "print(\"The shape of xtest:\", xtest.shape)\n",
    "print(\"The shape of ytest:\", ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "before training make we normalize the input data (features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmean = np.mean(xtrain_whole, axis=0)\n",
    "xstd = np.std(xtrain_whole, axis=0)\n",
    "xtrain_normal_whole = (xtrain_whole-xmean) / xstd\n",
    "xtest_normal = (xtest-xmean) / xstd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create a validation set. We create an array of indecies and permute it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "premute_indicies = np.random.permutation(np.arange(xtrain_whole.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We keep the first 2600 data points as the training data and rest as the validation data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_normal = xtrain_normal_whole[premute_indicies[:2600]]\n",
    "ytrain = ytrain_whole[premute_indicies[:2600]]\n",
    "xval_normal = xtrain_normal_whole[premute_indicies[2600:]]\n",
    "yval = ytrain_whole[premute_indicies[2600:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiallizing the weights and bias with random values from N(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.random.normal(0, 1, xtrain_normal.shape[1]);\n",
    "bias = np.random.normal(0,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the sigmoid function\n",
    "def sigmoid(v):\n",
    "    #return np.exp(-np.logaddexp(0, -v)) #numerically stable implementation of sigmoid function \n",
    "    return 1.0 / (1+np.exp(-v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use dot-product from numpy to calculate the margin and pass it to the sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#w: weight vector (numpy array of size n)\n",
    "#b: numpy array of size 1\n",
    "#returns p(y=1|x, w, b)\n",
    "def prob(x, w, b):\n",
    "    return sigmoid(np.dot(x,w) + b);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also calculate $l_2$ penalty using linalg library of numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.322867829192679"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{Cross Entropy Loss} = -\\sum_{(y^i,\\mathbf{x}^i)\\in\\mathcal{D}} \n",
    " y^i \\log p(y=1|\\mathbf{x}^i;\\mathbf{w},b)  +  (1-y^i) \\log (1 - p(y=1|\\mathbf{x}^i;\\mathbf{w},b)+\\frac{\\lambda}{2} \\|\\mathbf{w}\\|^2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#w: weight vector (numpy array of size n)\n",
    "#y_prob: p(y|x, w, b)\n",
    "#y_true: class variable data\n",
    "#lambda_: l2 penalty coefficient\n",
    "#returns the cross entropy loss\n",
    "def loss(w, y_prob, y_true, lambda_):\n",
    "    try: \n",
    "        EntropyLoss = 0\n",
    "        \n",
    "#       computing  y*log (p(y|x, w, b))\n",
    "        y_prob_1 = np.log(y_prob, out=np.zeros_like(y_prob), where=(y_prob!=0))\n",
    "        Probability_Y_1 = np.multiply(y_true,y_prob_1)\n",
    "        \n",
    "#       computing  (1-y)*log (1-p(y|x, w, b))\n",
    "        y_prob_0 = 1.0 - y_prob\n",
    "        y_prob_0 = np.log(y_prob_0, out=np.zeros_like(y_prob_0), where=(y_prob_0!=0))\n",
    "        Probability_Y_0 = np.multiply(1.0 - y_true,y_prob_0)\n",
    "        \n",
    "#       Calculating l2 penality and computing regularization\n",
    "        Regularization = lambda_/2 * np.linalg.norm(w, ord=2)\n",
    "#       Regularization = lambda_/2 * np.sum(w**2)\n",
    "\n",
    "        Probability = Probability_Y_1 + Probability_Y_0\n",
    "    \n",
    "#       calculating final cost value\n",
    "        EntropyLoss = (-1.0)*(np.sum(Probability) + Regularization)\n",
    "\n",
    "        raise NotImplementedError\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    return EntropyLoss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x: input variables (data of size m x n with m data point and n features)\n",
    "#w: weight vector (numpy array of size n)\n",
    "#y_prob: p(y|x, w, b)\n",
    "#y_true: class variable data\n",
    "#lambda_: l2 penalty coefficient\n",
    "#returns tuple of gradient w.r.t w and w.r.t to bias\n",
    "\n",
    "def grad_w_b(x, w, y_prob, y_true, lambda_):\n",
    "    grad_w = np.zeros(w.shape)\n",
    "    grad_b = 0.0\n",
    "    \n",
    "    try:\n",
    "#       expanding dimensions of weights vector from (54,) to (54,1)\n",
    "        grad_w = np.expand_dims(grad_w, axis=1)\n",
    "    \n",
    "#       computing gradient of loss function, dJ \n",
    "        grad_J = y_prob - y_true \n",
    "    \n",
    "#       computing gradient w.r.to weigths ,dJ/dW\n",
    "        grad_w = np.dot(x.T,grad_J) + lambda_ * w\n",
    "    \n",
    "#       computing gradient w.r.to bias ,dJ/db\n",
    "        grad_b = [np.sum(grad_J)]\n",
    "        grad_b = np.asarray(grad_b)\n",
    "\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "   \n",
    "    return (grad_w,grad_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#lambda_ is the coeffienct of l2 norm penalty\n",
    "#learning_rate is learning rate of gradient descent algorithm\n",
    "#max_iter determines the maximum number of iterations if the gradients descent does not converge.\n",
    "#continue the training while gradient > 0.1 or the number steps is less max_iter\n",
    "\n",
    "#returns model as tuple of (weights,bias)\n",
    "\n",
    "def fit(x, y_true, learning_rate, lambda_, max_iter, verbose=0):\n",
    "    weights = np.random.normal(0, 1, x.shape[1]);\n",
    "    bias = np.random.normal(0,1,1)\n",
    "    try: \n",
    "#       expanding dimensions of y_true and weights\n",
    "        y_true = np.expand_dims(y_true, axis=1)\n",
    "        weights = np.expand_dims(weights, axis=1)\n",
    "        \n",
    "        i=0\n",
    "#       computing norm of magnitude of weigths\n",
    "        gradient = np.linalg.norm(weights)\n",
    "    \n",
    "#       calculating y_probability y_prob: p(y|x, w, b)\n",
    "        y_prob = (prob(x, weights, bias)).astype(np.float)\n",
    "    \n",
    "#       calculating loss\n",
    "        cost = loss(weights,y_prob,y_true,lambda_)\n",
    "        \n",
    "#       stopping criterion, if gradient > 0.1 or the number steps is less max_iter\n",
    "        while i < max_iter and gradient > 0.1:\n",
    "        \n",
    "#           calculating gradient values\n",
    "            gradient_w,gradient_b = grad_w_b(x, weights, y_prob, y_true, lambda_)\n",
    "    \n",
    "#           updating the weights and bias values with respect to calculated gradient values\n",
    "            weights = weights - learning_rate * gradient_w\n",
    "            bias = bias - learning_rate * gradient_b\n",
    "        \n",
    "#           compute new loss value\n",
    "            y_prob = (prob(x, weights, bias)).astype(np.float)\n",
    "            cost_AfterGradients = loss(weights,y_prob,y_true,lambda_)\n",
    "            \n",
    "#           print(\"i =\",i,\" cost = \",cost,\" cost_AfterGradients \",cost_AfterGradients)\n",
    "            \n",
    "#           stopping condition, if the cost no more decreases\n",
    "            if(round(cost,5) <= round(cost_AfterGradients,5)):\n",
    "                break\n",
    "            \n",
    "#           computing norm of magnitude of weigths \n",
    "            gradient = np.linalg.norm(weights)\n",
    "    \n",
    "#           updating the new cost value\n",
    "            cost = cost_AfterGradients\n",
    "            i=i+1\n",
    "        \n",
    "#       change the dimensions of weights from (54,1) back to (54,)\n",
    "        weights.shape = np.squeeze(weights,axis = 1).shape\n",
    "\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    return (weights, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(x, y_true, model):\n",
    "    w, b = model\n",
    "    return np.sum((prob(x, w, b)>0.5).astype(np.float) == y_true)  / y_true.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "lambda_ = 1.0\n",
    "\n",
    "model = fit(xtrain_normal, ytrain, learning_rate, lambda_, 10000, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9315384615384615\n"
     ]
    }
   ],
   "source": [
    "print(\"Train accuracy: \", accuracy(xtrain_normal, ytrain, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#grid search for finding the best hyperparams and model\n",
    "\n",
    "best_model = None\n",
    "best_val = -1\n",
    "for lr in [0.01, 0.001, 0.0001, 0.00001]:\n",
    "    for la in [5, 2, 1, 0.1, 0.01]:\n",
    "        model = fit(xtrain_normal, ytrain, lr, la, 10000)\n",
    "        val_acc = accuracy(xval_normal, yval, model)\n",
    "        print(lr, la, val_acc)\n",
    "        if val_acc > best_val:\n",
    "            best_val = val_acc\n",
    "            best_model = model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.943\n"
     ]
    }
   ],
   "source": [
    "print(\"Test accuracy: \", accuracy(xtest_normal, ytest, best_model))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
